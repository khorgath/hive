PREHOOK: query: drop table if exists rdump_3
PREHOOK: type: DROPTABLE
POSTHOOK: query: drop table if exists rdump_3
POSTHOOK: type: DROPTABLE
PREHOOK: query: show databases
PREHOOK: type: SHOWDATABASES
POSTHOOK: query: show databases
POSTHOOK: type: SHOWDATABASES
default
PREHOOK: query: create table rdump_3(emp_id int comment "employee id")
        partitioned by (emp_country string, emp_state string)
        stored as textfile
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@rdump_3
POSTHOOK: query: create table rdump_3(emp_id int comment "employee id")
        partitioned by (emp_country string, emp_state string)
        stored as textfile
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@rdump_3
PREHOOK: query: load data local inpath "../../data/files/test.dat"
        into table rdump_3 partition (emp_country="us",emp_state="ca")
PREHOOK: type: LOAD
#### A masked pattern was here ####
PREHOOK: Output: default@rdump_3
POSTHOOK: query: load data local inpath "../../data/files/test.dat"
        into table rdump_3 partition (emp_country="us",emp_state="ca")
POSTHOOK: type: LOAD
#### A masked pattern was here ####
POSTHOOK: Output: default@rdump_3
POSTHOOK: Output: default@rdump_3@emp_country=us/emp_state=ca
PREHOOK: query: select count(*) from rdump_3
PREHOOK: type: QUERY
PREHOOK: Input: default@rdump_3
PREHOOK: Input: default@rdump_3@emp_country=us/emp_state=ca
#### A masked pattern was here ####
POSTHOOK: query: select count(*) from rdump_3
POSTHOOK: type: QUERY
POSTHOOK: Input: default@rdump_3
POSTHOOK: Input: default@rdump_3@emp_country=us/emp_state=ca
#### A masked pattern was here ####
0
PREHOOK: query: select * from rdump_3
PREHOOK: type: QUERY
PREHOOK: Input: default@rdump_3
PREHOOK: Input: default@rdump_3@emp_country=us/emp_state=ca
#### A masked pattern was here ####
POSTHOOK: query: select * from rdump_3
POSTHOOK: type: QUERY
POSTHOOK: Input: default@rdump_3
POSTHOOK: Input: default@rdump_3@emp_country=us/emp_state=ca
#### A masked pattern was here ####
PREHOOK: query: EXPLAIN REPL DUMP default
PREHOOK: type: EXPORT
POSTHOOK: query: EXPLAIN REPL DUMP default
POSTHOOK: type: EXPORT
STAGE DEPENDENCIES:
  Stage-0 is a root stage
  Stage-1 is a root stage
  Stage-2 is a root stage
  Stage-3 is a root stage
  Stage-4 is a root stage
  Stage-5 is a root stage
  Stage-6 is a root stage
  Stage-7 is a root stage
  Stage-8 is a root stage
  Stage-9 is a root stage
  Stage-10 is a root stage
  Stage-11 is a root stage
  Stage-12 is a root stage
  Stage-13 is a root stage
  Stage-14 is a root stage
  Stage-15 is a root stage
  Stage-16 is a root stage
  Stage-17 is a root stage
  Stage-18 is a root stage
  Stage-19 is a root stage
  Stage-20 is a root stage
  Stage-21 is a root stage
  Stage-22 is a root stage
  Stage-23 is a root stage
  Stage-24 is a root stage
  Stage-25 is a root stage
  Stage-26 is a root stage
  Stage-27 is a root stage
  Stage-28 is a root stage
  Stage-29 is a root stage
  Stage-30 is a root stage
  Stage-31 is a root stage
  Stage-32 is a root stage
  Stage-33 is a root stage
  Stage-34 is a root stage

STAGE PLANS:
  Stage: Stage-0
    Copy for Replication
#### A masked pattern was here ####

  Stage: Stage-1
    Copy for Replication
#### A masked pattern was here ####

  Stage: Stage-2
    Copy for Replication
#### A masked pattern was here ####

  Stage: Stage-3
    Copy for Replication
#### A masked pattern was here ####

  Stage: Stage-4
    Copy for Replication
#### A masked pattern was here ####

  Stage: Stage-5
    Copy for Replication
#### A masked pattern was here ####

  Stage: Stage-6
    Copy for Replication
#### A masked pattern was here ####

  Stage: Stage-7
    Copy for Replication
#### A masked pattern was here ####

  Stage: Stage-8
    Copy for Replication
#### A masked pattern was here ####

  Stage: Stage-9
    Copy for Replication
#### A masked pattern was here ####

  Stage: Stage-10
    Copy for Replication
#### A masked pattern was here ####

  Stage: Stage-11
    Copy for Replication
#### A masked pattern was here ####

  Stage: Stage-12
    Copy for Replication
#### A masked pattern was here ####

  Stage: Stage-13
    Copy for Replication
#### A masked pattern was here ####

  Stage: Stage-14
    Copy for Replication
#### A masked pattern was here ####

  Stage: Stage-15
    Copy for Replication
#### A masked pattern was here ####

  Stage: Stage-16
    Copy for Replication
#### A masked pattern was here ####

  Stage: Stage-17
    Copy for Replication
#### A masked pattern was here ####

  Stage: Stage-18
    Copy for Replication
#### A masked pattern was here ####

  Stage: Stage-19
    Copy for Replication
#### A masked pattern was here ####

  Stage: Stage-20
    Copy for Replication
#### A masked pattern was here ####

  Stage: Stage-21
    Copy for Replication
#### A masked pattern was here ####

  Stage: Stage-22
    Copy for Replication
#### A masked pattern was here ####

  Stage: Stage-23
    Copy for Replication
#### A masked pattern was here ####

  Stage: Stage-24
    Copy for Replication
#### A masked pattern was here ####

  Stage: Stage-25
    Copy for Replication
#### A masked pattern was here ####

  Stage: Stage-26
    Copy for Replication
#### A masked pattern was here ####

  Stage: Stage-27
    Copy for Replication
#### A masked pattern was here ####

  Stage: Stage-28
    Copy for Replication
#### A masked pattern was here ####

  Stage: Stage-29
    Copy for Replication
#### A masked pattern was here ####

  Stage: Stage-30
    Copy for Replication
#### A masked pattern was here ####

  Stage: Stage-31
    Copy for Replication
#### A masked pattern was here ####

  Stage: Stage-32
    Copy for Replication
#### A masked pattern was here ####

  Stage: Stage-33
    Copy for Replication
#### A masked pattern was here ####

  Stage: Stage-34
    Copy for Replication
#### A masked pattern was here ####

PREHOOK: query: REPL DUMP default
PREHOOK: type: EXPORT
PREHOOK: Input: default@alltypesorc
PREHOOK: Input: default@cbo_t1@dt=2014
PREHOOK: Input: default@cbo_t2@dt=2014
PREHOOK: Input: default@cbo_t3
PREHOOK: Input: default@lineitem
PREHOOK: Input: default@part
PREHOOK: Input: default@rdump_3@emp_country=us/emp_state=ca
PREHOOK: Input: default@src
PREHOOK: Input: default@src1
PREHOOK: Input: default@src_cbo
PREHOOK: Input: default@src_json
PREHOOK: Input: default@src_sequencefile
PREHOOK: Input: default@src_thrift
PREHOOK: Input: default@srcbucket
PREHOOK: Input: default@srcbucket2
PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
#### A masked pattern was here ####
POSTHOOK: query: REPL DUMP default
POSTHOOK: type: EXPORT
POSTHOOK: Input: default@alltypesorc
POSTHOOK: Input: default@cbo_t1@dt=2014
POSTHOOK: Input: default@cbo_t2@dt=2014
POSTHOOK: Input: default@cbo_t3
POSTHOOK: Input: default@lineitem
POSTHOOK: Input: default@part
POSTHOOK: Input: default@rdump_3@emp_country=us/emp_state=ca
POSTHOOK: Input: default@src
POSTHOOK: Input: default@src1
POSTHOOK: Input: default@src_cbo
POSTHOOK: Input: default@src_json
POSTHOOK: Input: default@src_sequencefile
POSTHOOK: Input: default@src_thrift
POSTHOOK: Input: default@srcbucket
POSTHOOK: Input: default@srcbucket2
POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
#### A masked pattern was here ####
PREHOOK: type: IMPORT
#### A masked pattern was here ####
POSTHOOK: type: IMPORT
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-3 depends on stages: Stage-1, Stage-2
  Stage-0 is a root stage
  Stage-2 depends on stages: Stage-0

STAGE PLANS:
  Stage: Stage-1
    Copy for Replication
#### A masked pattern was here ####

  Stage: Stage-3
    Move Operator
      tables:
          partition:
            emp_country us
            emp_state ca
          replace: true
          table:
              input format: org.apache.hadoop.mapred.SequenceFileInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
              name: default.rdump_4

  Stage: Stage-0
      Create Table Operator:
        Create Table
          columns: emp_id int employee id
          input format: org.apache.hadoop.mapred.TextInputFormat
#### A masked pattern was here ####
          output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
          partition columns: emp_country string, emp_state string
          serde name: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          serde properties:
            serialization.format 1
          name: rdump_4
          table properties:
            repl.last.id 0
#### A masked pattern was here ####

  Stage: Stage-2
      Add Partition Operator:
#### A masked pattern was here ####
          Spec: {emp_country=us, emp_state=ca}

#### A masked pattern was here ####
PREHOOK: type: IMPORT
#### A masked pattern was here ####
PREHOOK: Output: default@rdump_4
#### A masked pattern was here ####
POSTHOOK: type: IMPORT
#### A masked pattern was here ####
POSTHOOK: Output: default@rdump_4
POSTHOOK: Output: default@rdump_4@emp_country=us/emp_state=ca
PREHOOK: query: describe extended rdump_4
PREHOOK: type: DESCTABLE
PREHOOK: Input: default@rdump_4
POSTHOOK: query: describe extended rdump_4
POSTHOOK: type: DESCTABLE
POSTHOOK: Input: default@rdump_4
emp_id              	int                 	employee id         
emp_country         	string              	                    
emp_state           	string              	                    
	 	 
# Partition Information	 	 
# col_name            	data_type           	comment             
	 	 
emp_country         	string              	                    
emp_state           	string              	                    
	 	 
#### A masked pattern was here ####
PREHOOK: query: select count(*) from rdump_4
PREHOOK: type: QUERY
PREHOOK: Input: default@rdump_4
PREHOOK: Input: default@rdump_4@emp_country=us/emp_state=ca
#### A masked pattern was here ####
POSTHOOK: query: select count(*) from rdump_4
POSTHOOK: type: QUERY
POSTHOOK: Input: default@rdump_4
POSTHOOK: Input: default@rdump_4@emp_country=us/emp_state=ca
#### A masked pattern was here ####
0
PREHOOK: query: select * from rdump_4
PREHOOK: type: QUERY
PREHOOK: Input: default@rdump_4
PREHOOK: Input: default@rdump_4@emp_country=us/emp_state=ca
#### A masked pattern was here ####
POSTHOOK: query: select * from rdump_4
POSTHOOK: type: QUERY
POSTHOOK: Input: default@rdump_4
POSTHOOK: Input: default@rdump_4@emp_country=us/emp_state=ca
#### A masked pattern was here ####
PREHOOK: type: IMPORT
#### A masked pattern was here ####
POSTHOOK: type: IMPORT
STAGE DEPENDENCIES:
  Stage-0 is a root stage
  Stage-2 depends on stages: Stage-0
  Stage-3 depends on stages: Stage-2, Stage-1
  Stage-1 depends on stages: Stage-0
  Stage-5 depends on stages: Stage-0
  Stage-7 depends on stages: Stage-5, Stage-6
  Stage-4 depends on stages: Stage-0
  Stage-6 depends on stages: Stage-4
  Stage-9 depends on stages: Stage-0
  Stage-11 depends on stages: Stage-9, Stage-10
  Stage-8 depends on stages: Stage-0
  Stage-10 depends on stages: Stage-8
  Stage-13 depends on stages: Stage-0
  Stage-14 depends on stages: Stage-13, Stage-12
  Stage-12 depends on stages: Stage-0
  Stage-16 depends on stages: Stage-0
  Stage-17 depends on stages: Stage-16, Stage-15
  Stage-15 depends on stages: Stage-0
  Stage-19 depends on stages: Stage-0
  Stage-20 depends on stages: Stage-19, Stage-18
  Stage-18 depends on stages: Stage-0
  Stage-22 depends on stages: Stage-0
  Stage-24 depends on stages: Stage-22, Stage-23
  Stage-21 depends on stages: Stage-0
  Stage-23 depends on stages: Stage-21
  Stage-26 depends on stages: Stage-0
  Stage-27 depends on stages: Stage-26, Stage-25
  Stage-25 depends on stages: Stage-0
  Stage-29 depends on stages: Stage-0
  Stage-30 depends on stages: Stage-29, Stage-28
  Stage-28 depends on stages: Stage-0
  Stage-32 depends on stages: Stage-0
  Stage-33 depends on stages: Stage-32, Stage-31
  Stage-31 depends on stages: Stage-0
  Stage-35 depends on stages: Stage-0
  Stage-36 depends on stages: Stage-35, Stage-34
  Stage-34 depends on stages: Stage-0
  Stage-38 depends on stages: Stage-0
  Stage-39 depends on stages: Stage-38, Stage-37
  Stage-37 depends on stages: Stage-0
  Stage-41 depends on stages: Stage-0
  Stage-42 depends on stages: Stage-41, Stage-40
  Stage-40 depends on stages: Stage-0
  Stage-44 depends on stages: Stage-0
  Stage-45 depends on stages: Stage-44, Stage-43
  Stage-43 depends on stages: Stage-0
  Stage-47 depends on stages: Stage-0
  Stage-48 depends on stages: Stage-47, Stage-46
  Stage-46 depends on stages: Stage-0
  Stage-50 depends on stages: Stage-0
  Stage-52 depends on stages: Stage-50, Stage-51
  Stage-53 depends on stages: Stage-0
  Stage-55 depends on stages: Stage-53, Stage-54
  Stage-56 depends on stages: Stage-0
  Stage-58 depends on stages: Stage-56, Stage-57
  Stage-59 depends on stages: Stage-0
  Stage-61 depends on stages: Stage-59, Stage-60
  Stage-49 depends on stages: Stage-0
  Stage-51 depends on stages: Stage-49
  Stage-54 depends on stages: Stage-49
  Stage-57 depends on stages: Stage-49
  Stage-60 depends on stages: Stage-49

STAGE PLANS:
  Stage: Stage-0

  Stage: Stage-2
    Copy for Replication
#### A masked pattern was here ####

  Stage: Stage-3
    Move Operator
      tables:
          replace: true
          table:
              input format: org.apache.hadoop.mapred.SequenceFileInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
              name: backup.alltypesorc

  Stage: Stage-1
      Create Table Operator:
        Create Table
          columns: ctinyint tinyint, csmallint smallint, cint int, cbigint bigint, cfloat float, cdouble double, cstring1 string, cstring2 string, ctimestamp1 timestamp, ctimestamp2 timestamp, cboolean1 boolean, cboolean2 boolean
          input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
#### A masked pattern was here ####
          output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
          serde name: org.apache.hadoop.hive.ql.io.orc.OrcSerde
          serde properties:
            serialization.format 1
          name: alltypesorc
          table properties:
            COLUMN_STATS_ACCURATE {"COLUMN_STATS":{"cbigint":"true","cboolean1":"true","cboolean2":"true","cdouble":"true","cfloat":"true","cint":"true","csmallint":"true","cstring1":"true","cstring2":"true","ctimestamp1":"true","ctimestamp2":"true","ctinyint":"true"},"BASIC_STATS":"true"}
            DO_NOT_UPDATE_STATS true
            numFiles 1
            numRows 12288
            rawDataSize 2641964
            repl.last.id 0
            totalSize 377237
#### A masked pattern was here ####

  Stage: Stage-5
    Copy for Replication
#### A masked pattern was here ####

  Stage: Stage-7
    Move Operator
      tables:
          partition:
            dt 2014
          replace: true
          table:
              input format: org.apache.hadoop.mapred.SequenceFileInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
              name: backup.cbo_t1

  Stage: Stage-4
      Create Table Operator:
        Create Table
          columns: key string, value string, c_int int, c_float float, c_boolean boolean
          input format: org.apache.hadoop.mapred.TextInputFormat
#### A masked pattern was here ####
          output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
          partition columns: dt string
          serde name: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          serde properties:
            field.delim ,
            serialization.format ,
          name: cbo_t1
          table properties:
            repl.last.id 0
#### A masked pattern was here ####

  Stage: Stage-6
      Add Partition Operator:
#### A masked pattern was here ####
          Spec: {dt=2014}

  Stage: Stage-9
    Copy for Replication
#### A masked pattern was here ####

  Stage: Stage-11
    Move Operator
      tables:
          partition:
            dt 2014
          replace: true
          table:
              input format: org.apache.hadoop.mapred.SequenceFileInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
              name: backup.cbo_t2

  Stage: Stage-8
      Create Table Operator:
        Create Table
          columns: key string, value string, c_int int, c_float float, c_boolean boolean
          input format: org.apache.hadoop.mapred.TextInputFormat
#### A masked pattern was here ####
          output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
          partition columns: dt string
          serde name: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          serde properties:
            field.delim ,
            serialization.format ,
          name: cbo_t2
          table properties:
            repl.last.id 0
#### A masked pattern was here ####

  Stage: Stage-10
      Add Partition Operator:
#### A masked pattern was here ####
          Spec: {dt=2014}

  Stage: Stage-13
    Copy for Replication
#### A masked pattern was here ####

  Stage: Stage-14
    Move Operator
      tables:
          replace: true
          table:
              input format: org.apache.hadoop.mapred.SequenceFileInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
              name: backup.cbo_t3

  Stage: Stage-12
      Create Table Operator:
        Create Table
          columns: key string, value string, c_int int, c_float float, c_boolean boolean
          input format: org.apache.hadoop.mapred.TextInputFormat
#### A masked pattern was here ####
          output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
          serde name: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          serde properties:
            field.delim ,
            serialization.format ,
          name: cbo_t3
          table properties:
            COLUMN_STATS_ACCURATE {"COLUMN_STATS":{"c_boolean":"true","c_float":"true","c_int":"true","key":"true","value":"true"},"BASIC_STATS":"true"}
            DO_NOT_UPDATE_STATS true
            numFiles 1
            numRows 20
            rawDataSize 262
            repl.last.id 0
            totalSize 282
#### A masked pattern was here ####

  Stage: Stage-16
    Copy for Replication
#### A masked pattern was here ####

  Stage: Stage-17
    Move Operator
      tables:
          replace: true
          table:
              input format: org.apache.hadoop.mapred.SequenceFileInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
              name: backup.lineitem

  Stage: Stage-15
      Create Table Operator:
        Create Table
          columns: l_orderkey int, l_partkey int, l_suppkey int, l_linenumber int, l_quantity double, l_extendedprice double, l_discount double, l_tax double, l_returnflag string, l_linestatus string, l_shipdate string, l_commitdate string, l_receiptdate string, l_shipinstruct string, l_shipmode string, l_comment string
          input format: org.apache.hadoop.mapred.TextInputFormat
#### A masked pattern was here ####
          output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
          serde name: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          serde properties:
            field.delim |
            serialization.format |
          name: lineitem
          table properties:
            COLUMN_STATS_ACCURATE {"COLUMN_STATS":{"l_comment":"true","l_commitdate":"true","l_discount":"true","l_extendedprice":"true","l_linenumber":"true","l_linestatus":"true","l_orderkey":"true","l_partkey":"true","l_quantity":"true","l_receiptdate":"true","l_returnflag":"true","l_shipdate":"true","l_shipinstruct":"true","l_shipmode":"true","l_suppkey":"true","l_tax":"true"},"BASIC_STATS":"true"}
            DO_NOT_UPDATE_STATS true
            numFiles 1
            numRows 100
            rawDataSize 11999
            repl.last.id 0
            totalSize 12099
#### A masked pattern was here ####

  Stage: Stage-19
    Copy for Replication
#### A masked pattern was here ####

  Stage: Stage-20
    Move Operator
      tables:
          replace: true
          table:
              input format: org.apache.hadoop.mapred.SequenceFileInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
              name: backup.part

  Stage: Stage-18
      Create Table Operator:
        Create Table
          columns: p_partkey int, p_name string, p_mfgr string, p_brand string, p_type string, p_size int, p_container string, p_retailprice double, p_comment string
          input format: org.apache.hadoop.mapred.TextInputFormat
#### A masked pattern was here ####
          output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
          serde name: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          serde properties:
            serialization.format 1
          name: part
          table properties:
            COLUMN_STATS_ACCURATE {"COLUMN_STATS":{"p_brand":"true","p_comment":"true","p_container":"true","p_mfgr":"true","p_name":"true","p_partkey":"true","p_retailprice":"true","p_size":"true","p_type":"true"},"BASIC_STATS":"true"}
            DO_NOT_UPDATE_STATS true
            numFiles 1
            numRows 26
            rawDataSize 3147
            repl.last.id 0
            totalSize 3173
#### A masked pattern was here ####

  Stage: Stage-22
    Copy for Replication
#### A masked pattern was here ####

  Stage: Stage-24
    Move Operator
      tables:
          partition:
            emp_country us
            emp_state ca
          replace: true
          table:
              input format: org.apache.hadoop.mapred.SequenceFileInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
              name: backup.rdump_3

  Stage: Stage-21
      Create Table Operator:
        Create Table
          columns: emp_id int employee id
          input format: org.apache.hadoop.mapred.TextInputFormat
#### A masked pattern was here ####
          output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
          partition columns: emp_country string, emp_state string
          serde name: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          serde properties:
            serialization.format 1
          name: rdump_3
          table properties:
            repl.last.id 0
#### A masked pattern was here ####

  Stage: Stage-23
      Add Partition Operator:
#### A masked pattern was here ####
          Spec: {emp_country=us, emp_state=ca}

  Stage: Stage-26
    Copy for Replication
#### A masked pattern was here ####

  Stage: Stage-27
    Move Operator
      tables:
          replace: true
          table:
              input format: org.apache.hadoop.mapred.SequenceFileInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
              name: backup.src

  Stage: Stage-25
      Create Table Operator:
        Create Table
          columns: key string default, value string default
          input format: org.apache.hadoop.mapred.TextInputFormat
#### A masked pattern was here ####
          output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
          serde name: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          serde properties:
            serialization.format 1
          name: src
          table properties:
            COLUMN_STATS_ACCURATE {"COLUMN_STATS":{"key":"true","value":"true"},"BASIC_STATS":"true"}
            DO_NOT_UPDATE_STATS true
            numFiles 1
            numRows 500
            rawDataSize 5312
            repl.last.id 0
            totalSize 5812
#### A masked pattern was here ####

  Stage: Stage-29
    Copy for Replication
#### A masked pattern was here ####

  Stage: Stage-30
    Move Operator
      tables:
          replace: true
          table:
              input format: org.apache.hadoop.mapred.SequenceFileInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
              name: backup.src1

  Stage: Stage-28
      Create Table Operator:
        Create Table
          columns: key string default, value string default
          input format: org.apache.hadoop.mapred.TextInputFormat
#### A masked pattern was here ####
          output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
          serde name: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          serde properties:
            serialization.format 1
          name: src1
          table properties:
            COLUMN_STATS_ACCURATE {"COLUMN_STATS":{"key":"true","value":"true"},"BASIC_STATS":"true"}
            DO_NOT_UPDATE_STATS true
            numFiles 1
            numRows 25
            rawDataSize 191
            repl.last.id 0
            totalSize 216
#### A masked pattern was here ####

  Stage: Stage-32
    Copy for Replication
#### A masked pattern was here ####

  Stage: Stage-33
    Move Operator
      tables:
          replace: true
          table:
              input format: org.apache.hadoop.mapred.SequenceFileInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
              name: backup.src_cbo

  Stage: Stage-31
      Create Table Operator:
        Create Table
          columns: key string, value string
          input format: org.apache.hadoop.mapred.TextInputFormat
#### A masked pattern was here ####
          output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
          serde name: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          serde properties:
            serialization.format 1
          name: src_cbo
          table properties:
            COLUMN_STATS_ACCURATE {"COLUMN_STATS":{"key":"true","value":"true"},"BASIC_STATS":"true"}
            DO_NOT_UPDATE_STATS true
            numFiles 1
            numRows 500
            rawDataSize 5312
            repl.last.id 0
            totalSize 5812
#### A masked pattern was here ####

  Stage: Stage-35
    Copy for Replication
#### A masked pattern was here ####

  Stage: Stage-36
    Move Operator
      tables:
          replace: true
          table:
              input format: org.apache.hadoop.mapred.SequenceFileInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
              name: backup.src_json

  Stage: Stage-34
      Create Table Operator:
        Create Table
          columns: json string default
          input format: org.apache.hadoop.mapred.TextInputFormat
#### A masked pattern was here ####
          output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
          serde name: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          serde properties:
            serialization.format 1
          name: src_json
          table properties:
            COLUMN_STATS_ACCURATE {"COLUMN_STATS":{"json":"true"},"BASIC_STATS":"true"}
            DO_NOT_UPDATE_STATS true
            numFiles 1
            numRows 1
            rawDataSize 644
            repl.last.id 0
            totalSize 645
#### A masked pattern was here ####

  Stage: Stage-38
    Copy for Replication
#### A masked pattern was here ####

  Stage: Stage-39
    Move Operator
      tables:
          replace: true
          table:
              input format: org.apache.hadoop.mapred.SequenceFileInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
              name: backup.src_sequencefile

  Stage: Stage-37
      Create Table Operator:
        Create Table
          columns: key string default, value string default
          input format: org.apache.hadoop.mapred.SequenceFileInputFormat
#### A masked pattern was here ####
          output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
          serde name: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          serde properties:
            serialization.format 1
          name: src_sequencefile
          table properties:
            COLUMN_STATS_ACCURATE {"COLUMN_STATS":{"key":"true","value":"true"},"BASIC_STATS":"true"}
            DO_NOT_UPDATE_STATS true
            numFiles 1
            numRows 500
            rawDataSize 5312
            repl.last.id 0
            totalSize 10508
#### A masked pattern was here ####

  Stage: Stage-41
    Copy for Replication
#### A masked pattern was here ####

  Stage: Stage-42
    Move Operator
      tables:
          replace: true
          table:
              input format: org.apache.hadoop.mapred.SequenceFileInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
              name: backup.src_thrift

  Stage: Stage-40
      Create Table Operator:
        Create Table
          columns: aint int from deserializer, astring string from deserializer, lint array<int> from deserializer, lstring array<string> from deserializer, lintstring array<struct<myint:int,mystring:string,underscore_int:int>> from deserializer, mstringstring map<string,string> from deserializer, attributes map<string,map<string,map<string,uniontype<int,bigint,string,double,boolean,array<string>,map<string,string>>>>> from deserializer, unionfield1 uniontype<int,bigint,string,double,boolean,array<string>,map<string,string>> from deserializer, unionfield2 uniontype<int,bigint,string,double,boolean,array<string>,map<string,string>> from deserializer, unionfield3 uniontype<int,bigint,string,double,boolean,array<string>,map<string,string>> from deserializer
          input format: org.apache.hadoop.mapred.SequenceFileInputFormat
#### A masked pattern was here ####
          output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
          serde name: org.apache.hadoop.hive.serde2.thrift.ThriftDeserializer
          serde properties:
            serialization.class org.apache.hadoop.hive.serde2.thrift.test.Complex
#### A masked pattern was here ####
          name: src_thrift
          table properties:
            COLUMN_STATS_ACCURATE {"BASIC_STATS":"true"}
            DO_NOT_UPDATE_STATS true
            numFiles 1
            numRows 11
            rawDataSize 0
            repl.last.id 0
            totalSize 3070
#### A masked pattern was here ####

  Stage: Stage-44
    Copy for Replication
#### A masked pattern was here ####

  Stage: Stage-45
    Move Operator
      tables:
          replace: true
          table:
              input format: org.apache.hadoop.mapred.SequenceFileInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
              name: backup.srcbucket

  Stage: Stage-43
      Create Table Operator:
        Create Table
          bucket columns: key
          columns: key int, value string
          input format: org.apache.hadoop.mapred.TextInputFormat
#### A masked pattern was here ####
          # buckets: 2
          output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
          serde name: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          serde properties:
            serialization.format 1
          name: srcbucket
          table properties:
            COLUMN_STATS_ACCURATE {"COLUMN_STATS":{"key":"true","value":"true"},"BASIC_STATS":"true"}
            DO_NOT_UPDATE_STATS true
            numFiles 2
            numRows 1000
            rawDataSize 10603
            repl.last.id 0
            totalSize 11603
#### A masked pattern was here ####

  Stage: Stage-47
    Copy for Replication
#### A masked pattern was here ####

  Stage: Stage-48
    Move Operator
      tables:
          replace: true
          table:
              input format: org.apache.hadoop.mapred.SequenceFileInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
              name: backup.srcbucket2

  Stage: Stage-46
      Create Table Operator:
        Create Table
          bucket columns: key
          columns: key int, value string
          input format: org.apache.hadoop.mapred.TextInputFormat
#### A masked pattern was here ####
          # buckets: 4
          output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
          serde name: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          serde properties:
            serialization.format 1
          name: srcbucket2
          table properties:
            COLUMN_STATS_ACCURATE {"COLUMN_STATS":{"key":"true","value":"true"},"BASIC_STATS":"true"}
            DO_NOT_UPDATE_STATS true
            numFiles 4
            numRows 500
            rawDataSize 5312
            repl.last.id 0
            totalSize 5812
#### A masked pattern was here ####

  Stage: Stage-50
    Copy for Replication
#### A masked pattern was here ####

  Stage: Stage-52
    Move Operator
      tables:
          partition:
            ds 2008-04-08
            hr 11
          replace: true
          table:
              input format: org.apache.hadoop.mapred.SequenceFileInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
              name: backup.srcpart

  Stage: Stage-53
    Copy for Replication
#### A masked pattern was here ####

  Stage: Stage-55
    Move Operator
      tables:
          partition:
            ds 2008-04-08
            hr 12
          replace: true
          table:
              input format: org.apache.hadoop.mapred.SequenceFileInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
              name: backup.srcpart

  Stage: Stage-56
    Copy for Replication
#### A masked pattern was here ####

  Stage: Stage-58
    Move Operator
      tables:
          partition:
            ds 2008-04-09
            hr 11
          replace: true
          table:
              input format: org.apache.hadoop.mapred.SequenceFileInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
              name: backup.srcpart

  Stage: Stage-59
    Copy for Replication
#### A masked pattern was here ####

  Stage: Stage-61
    Move Operator
      tables:
          partition:
            ds 2008-04-09
            hr 12
          replace: true
          table:
              input format: org.apache.hadoop.mapred.SequenceFileInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              serde: org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe
              name: backup.srcpart

  Stage: Stage-49
      Create Table Operator:
        Create Table
          columns: key string default, value string default
          input format: org.apache.hadoop.mapred.TextInputFormat
#### A masked pattern was here ####
          output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
          partition columns: ds string, hr string
          serde name: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          serde properties:
            serialization.format 1
          name: srcpart
          table properties:
            repl.last.id 0
#### A masked pattern was here ####

  Stage: Stage-51
      Add Partition Operator:
#### A masked pattern was here ####
          Spec: {ds=2008-04-08, hr=11}

  Stage: Stage-54
      Add Partition Operator:
#### A masked pattern was here ####
          Spec: {ds=2008-04-08, hr=12}

  Stage: Stage-57
      Add Partition Operator:
#### A masked pattern was here ####
          Spec: {ds=2008-04-09, hr=11}

  Stage: Stage-60
      Add Partition Operator:
#### A masked pattern was here ####
          Spec: {ds=2008-04-09, hr=12}

#### A masked pattern was here ####
PREHOOK: type: IMPORT
#### A masked pattern was here ####
PREHOOK: Output: backup@alltypesorc
PREHOOK: Output: backup@cbo_t1
PREHOOK: Output: backup@cbo_t2
PREHOOK: Output: backup@cbo_t3
PREHOOK: Output: backup@lineitem
PREHOOK: Output: backup@part
PREHOOK: Output: backup@rdump_3
PREHOOK: Output: backup@src
PREHOOK: Output: backup@src1
PREHOOK: Output: backup@src_cbo
PREHOOK: Output: backup@src_json
PREHOOK: Output: backup@src_sequencefile
PREHOOK: Output: backup@src_thrift
PREHOOK: Output: backup@srcbucket
PREHOOK: Output: backup@srcbucket2
PREHOOK: Output: backup@srcpart
#### A masked pattern was here ####
POSTHOOK: type: IMPORT
#### A masked pattern was here ####
POSTHOOK: Output: backup@alltypesorc
POSTHOOK: Output: backup@cbo_t1
POSTHOOK: Output: backup@cbo_t1@dt=2014
POSTHOOK: Output: backup@cbo_t2
POSTHOOK: Output: backup@cbo_t2@dt=2014
POSTHOOK: Output: backup@cbo_t3
POSTHOOK: Output: backup@lineitem
POSTHOOK: Output: backup@part
POSTHOOK: Output: backup@rdump_3
POSTHOOK: Output: backup@rdump_3@emp_country=us/emp_state=ca
POSTHOOK: Output: backup@src
POSTHOOK: Output: backup@src1
POSTHOOK: Output: backup@src_cbo
POSTHOOK: Output: backup@src_json
POSTHOOK: Output: backup@src_sequencefile
POSTHOOK: Output: backup@src_thrift
POSTHOOK: Output: backup@srcbucket
POSTHOOK: Output: backup@srcbucket2
POSTHOOK: Output: backup@srcpart
POSTHOOK: Output: backup@srcpart@ds=2008-04-08/hr=11
POSTHOOK: Output: backup@srcpart@ds=2008-04-08/hr=12
POSTHOOK: Output: backup@srcpart@ds=2008-04-09/hr=11
POSTHOOK: Output: backup@srcpart@ds=2008-04-09/hr=12
PREHOOK: query: REPL STATUS backup
PREHOOK: type: SHOW_TBLPROPERTIES
PREHOOK: Input: database:backup
POSTHOOK: query: REPL STATUS backup
POSTHOOK: type: SHOW_TBLPROPERTIES
POSTHOOK: Input: database:backup
NULL
PREHOOK: query: use backup
PREHOOK: type: SWITCHDATABASE
PREHOOK: Input: database:backup
POSTHOOK: query: use backup
POSTHOOK: type: SWITCHDATABASE
POSTHOOK: Input: database:backup
PREHOOK: query: show tables
PREHOOK: type: SHOWTABLES
PREHOOK: Input: database:backup
POSTHOOK: query: show tables
POSTHOOK: type: SHOWTABLES
POSTHOOK: Input: database:backup
alltypesorc
cbo_t1
cbo_t2
cbo_t3
lineitem
part
rdump_3
src
src1
src_cbo
src_json
src_sequencefile
src_thrift
srcbucket
srcbucket2
srcpart
PREHOOK: query: select count(*) from rdump_3
PREHOOK: type: QUERY
PREHOOK: Input: backup@rdump_3
PREHOOK: Input: backup@rdump_3@emp_country=us/emp_state=ca
#### A masked pattern was here ####
POSTHOOK: query: select count(*) from rdump_3
POSTHOOK: type: QUERY
POSTHOOK: Input: backup@rdump_3
POSTHOOK: Input: backup@rdump_3@emp_country=us/emp_state=ca
#### A masked pattern was here ####
0
PREHOOK: query: select * from rdump_3
PREHOOK: type: QUERY
PREHOOK: Input: backup@rdump_3
PREHOOK: Input: backup@rdump_3@emp_country=us/emp_state=ca
#### A masked pattern was here ####
POSTHOOK: query: select * from rdump_3
POSTHOOK: type: QUERY
POSTHOOK: Input: backup@rdump_3
POSTHOOK: Input: backup@rdump_3@emp_country=us/emp_state=ca
#### A masked pattern was here ####
PREHOOK: query: drop table rdump_3
PREHOOK: type: DROPTABLE
PREHOOK: Input: backup@rdump_3
PREHOOK: Output: backup@rdump_3
POSTHOOK: query: drop table rdump_3
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: backup@rdump_3
POSTHOOK: Output: backup@rdump_3
PREHOOK: query: drop table default.rdump_4
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@rdump_4
PREHOOK: Output: default@rdump_4
POSTHOOK: query: drop table default.rdump_4
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@rdump_4
POSTHOOK: Output: default@rdump_4
